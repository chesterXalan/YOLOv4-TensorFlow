{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 套件載入 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "套件載入完成\n"
     ]
    }
   ],
   "source": [
    "import os        \n",
    "import cv2\n",
    "import json\n",
    "import pafy\n",
    "import numpy as np\n",
    "import core.utils as utils\n",
    "from time import time, sleep\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from tensorflow.compat.v1 import ConfigProto, InteractiveSession\n",
    "from tensorflow.python.saved_model import tag_constants\n",
    "\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "\n",
    "print('套件載入完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型載入、GPU初次啟動 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型載入、GPU初次啟動完成\n"
     ]
    }
   ],
   "source": [
    "set_size = 416 # set image size to 416\n",
    "set_weights = r'.\\checkpoints\\yolov4-' + str(set_size) # path to weights file\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5 # 設定GPU快取為50% GPU記憶體\n",
    "session = InteractiveSession(config = config)\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(set_weights, tags = [tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']\n",
    "\n",
    "array_for_activate = np.zeros((set_size, set_size, 3))\n",
    "array_for_activate = np.asarray([array_for_activate / 255]).astype(np.float32)\n",
    "batch_data = tf.constant(array_for_activate)\n",
    "pred_bbox = infer(batch_data)\n",
    "\n",
    "print('模型載入、GPU初次啟動完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 主要路徑設定、物件名稱載入 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorbike', 4: 'aeroplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'sofa', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tvmonitor', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "\n",
      "主要路徑設定、物件名稱載入完成\n"
     ]
    }
   ],
   "source": [
    "set_image_input = r'.\\data\\input_images' # path to image input\n",
    "set_video_input = r'.\\data\\input_videos' # path to video input\n",
    "set_image_output = r'.\\data\\output_images' # path to image output\n",
    "set_video_output = r'.\\data\\output_videos' # path to video output\n",
    "if not os.path.exists(set_image_output): os.mkdir(set_image_output)\n",
    "if not os.path.exists(set_video_output): os.mkdir(set_video_output)\n",
    "\n",
    "set_names_file = r'.\\data\\classes\\coco.names' # path to class names file\n",
    "names = utils.read_class_names(set_names_file)\n",
    "print(names)\n",
    "\n",
    "print('\\n主要路徑設定、物件名稱載入完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函式宣告 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "函式宣告完成\n"
     ]
    }
   ],
   "source": [
    "def preProcessing(img):\n",
    "    img = cv2.resize(img, (set_size, set_size))\n",
    "    img = np.asarray([img / 255]).astype(np.float32)\n",
    "    return img\n",
    "    \n",
    "def detection(img):\n",
    "    start_time = time()\n",
    "    batch_data = tf.constant(img)\n",
    "    pred_bbox = infer(batch_data)\n",
    "    for _, value in pred_bbox.items():\n",
    "        boxes = value[:, :, :4]\n",
    "        pred_conf = value[:, :, 4:]\n",
    "        \n",
    "    boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "        boxes = tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "        scores = tf.reshape(pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "        max_output_size_per_class = 50,\n",
    "        max_total_size = 50,\n",
    "        iou_threshold = 0.45,\n",
    "        score_threshold = 0.35\n",
    "    )\n",
    "    bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
    "    dtime = time() - start_time\n",
    "    return bbox, dtime\n",
    "    \n",
    "def objectFilter(bbox, obj):\n",
    "    Box, Score, Class, Quantity = bbox\n",
    "    for i in range(Quantity[0]):\n",
    "        if int(Class[0, i]) not in obj:\n",
    "            Box[0, i] = np.asarray([0., 0., 0., 0.]) # [0. 0. 0. 0.]\n",
    "            Score[0, i] = 0.\n",
    "            Class[0, i] = 0.\n",
    "    bbox = [Box, Score, Class, Quantity]\n",
    "    return bbox\n",
    "    \n",
    "def drawImage(img, bbox):\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = utils.draw_bbox(img, bbox)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    return img\n",
    "    \n",
    "def showResult(mode, img):\n",
    "    cv2.imshow('Detection_Result', img)\n",
    "    if mode == 'image':\n",
    "        cv2.waitKey(0)\n",
    "    elif mode == 'video':\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "            \n",
    "def writeFile(ind, img, bbox):\n",
    "    json_data = []\n",
    "    Box, Score, Class, Quantity = bbox\n",
    "    for i in range(Quantity[0]):\n",
    "        if Score[0, i] != 0.:\n",
    "            Jbox = [int(box) for box in Box[0, i]]\n",
    "            Jscore = float('%.2f' % (Score[0, i]))\n",
    "            Jname = names[int(Class[0, i])]\n",
    "            json_data.append({'bounding_box': Jbox, 'confidence': Jscore, 'object': Jname})\n",
    "            \n",
    "    cv2.imwrite(output_paths[ind], img)\n",
    "    with open(json_paths[ind], 'w') as f:\n",
    "        for d in json_data:\n",
    "            f.write(json.dumps(d))\n",
    "            f.write('\\n')\n",
    "    if ind == 0:\n",
    "        print('\\n已儲存圖片與偵測資訊到路徑：')\n",
    "    print('%2d: %s(.json)' % (ind + 1, os.getcwd() + output_paths[ind][1:]))\n",
    "    \n",
    "def releaseVideo():\n",
    "    cv2.destroyAllWindows()\n",
    "    input_video.release()\n",
    "    if write_video:\n",
    "        output_video.release()\n",
    "        print('已儲存影片到路徑：%s' % (os.getcwd() + output_path[1:]))\n",
    "    \n",
    "def printString(string, amount = 50):\n",
    "    print('=' * amount, string, '=' * amount)\n",
    "    \n",
    "def processingTime(mode, time_prc, time_det, cnt):\n",
    "    if mode == 'video':\n",
    "        clear_output(wait = True)\n",
    "    print('總處理時間：%.3f秒' % time_prc)\n",
    "    print('平均處理時間：%.3f秒' % (time_prc / cnt))\n",
    "    print('平均偵測時間：%.3f秒' % (time_det / cnt))\n",
    "    \n",
    "print('函式宣告完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 圖片物件偵測 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已讀取3個圖片路徑：\n",
      " 1: D:\\User Profiles\\Desktop\\Project\\TensorFlow-YOLOv4\\data\\input_images\\2174659396_374dd3c6f3_z.jpg\n",
      " 2: D:\\User Profiles\\Desktop\\Project\\TensorFlow-YOLOv4\\data\\input_images\\3689297032_cac37fd7a8_z.jpg\n",
      " 3: D:\\User Profiles\\Desktop\\Project\\TensorFlow-YOLOv4\\data\\input_images\\9523522126_171a47db50_z.jpg\n",
      "\n",
      "已儲存圖片與偵測資訊到路徑：\n",
      " 1: D:\\User Profiles\\Desktop\\Project\\TensorFlow-YOLOv4\\data\\output_images\\2174659396_374dd3c6f3_z.jpg(.json)\n",
      " 2: D:\\User Profiles\\Desktop\\Project\\TensorFlow-YOLOv4\\data\\output_images\\3689297032_cac37fd7a8_z.jpg(.json)\n",
      " 3: D:\\User Profiles\\Desktop\\Project\\TensorFlow-YOLOv4\\data\\output_images\\9523522126_171a47db50_z.jpg(.json)\n",
      "========================================================== 圖片物件偵測完成 ==========================================================\n",
      "總處理時間：0.460秒\n",
      "平均處理時間：0.153秒\n",
      "平均偵測時間：0.059秒\n"
     ]
    }
   ],
   "source": [
    "write_file = True # 是否寫入檔案\n",
    "all_images = False # 是否讀取'data\\input_images'內所有檔案\n",
    "if all_images:\n",
    "    files = os.listdir(set_image_input)\n",
    "else:\n",
    "    files = ['2174659396_374dd3c6f3_z.jpg', '3689297032_cac37fd7a8_z.jpg', '9523522126_171a47db50_z.jpg'] # 若否，則指定檔案\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "input_paths = [os.path.join(set_image_input, f) for f in files]\n",
    "output_paths = [os.path.join(set_image_output, f) for f in files]\n",
    "json_paths = [os.path.join(set_image_output, f.split('.')[0] + '.json') for f in files]\n",
    "\n",
    "print('已讀取%d個圖片路徑：' % len(files))\n",
    "for i, path in enumerate(input_paths):\n",
    "    print('%2d: %s' % (i + 1, os.getcwd() + path[1:]))\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "all_object = True # 是否標記所有物件\n",
    "particular_obj = [0, 2] # 若否，則指定物件\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "detection_time = 0\n",
    "results = []\n",
    "input_images = [cv2.imread(img) for img in input_paths]\n",
    "\n",
    "start_time = time()\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "for i, ipimg in enumerate(input_images):\n",
    "    image = ipimg\n",
    "    image_pre = preProcessing(image)\n",
    "    \n",
    "    bounding_box, det_time = detection(image_pre)\n",
    "    detection_time += det_time\n",
    "    \n",
    "    if not all_object:\n",
    "        bounding_box = objectFilter(bounding_box, particular_obj)\n",
    "    image_drw = drawImage(image, bounding_box)\n",
    "    results.append(image_drw)\n",
    "    \n",
    "    if write_file:\n",
    "        writeFile(i, image_drw, bounding_box)\n",
    "    \n",
    "printString('圖片物件偵測完成', 58)\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "processingTime('image', time() - start_time, detection_time,  len(files))\n",
    "\n",
    "cv2.namedWindow('Detection_Result', cv2.WINDOW_AUTOSIZE)\n",
    "for i in range(len(results)):\n",
    "    showResult('image', results[i])\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取YouTube網址 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已讀取影片網址：https://www.youtube.com/watch?v=oA9g8KBY5r8\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.youtube.com/watch?v=oA9g8KBY5r8' # video url\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "video = pafy.new(url)\n",
    "file_name = video.videoid\n",
    "for vst in video.videostreams:\n",
    "    if str(vst) == 'video:mp4@1280x720':\n",
    "        video720p = vst # get resolution 1280x720 mp4 (if exist)\n",
    "        break\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "input_path = video720p.url\n",
    "output_path = os.path.join(set_video_output, file_name + '.avi')\n",
    "print('已讀取影片網址：%s' % url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下載YouTube影片 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  207,848,681.0 Bytes [100.00%] received. Rate: [35620 KB/s].  ETA: [0 secs]    \n"
     ]
    }
   ],
   "source": [
    "video720p.download(filepath = os.path.join(set_video_input, file_name + '.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取影片檔案 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已讀取影片路徑：D:\\User Profiles\\Desktop\\Personal\\Project\\YOLOv4-TensorFlow\\data\\input_videos\\oA9g8KBY5r8.mp4\n"
     ]
    }
   ],
   "source": [
    "file = 'oA9g8KBY5r8.mp4' # video file\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "input_path = os.path.join(set_video_input, file)\n",
    "output_path = os.path.join(set_video_output, file.split('.')[0] + '.avi')\n",
    "print('已讀取影片路徑：%s' % (os.getcwd() + input_path[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 影片物件偵測 w/多執行緒 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總處理時間：17.993秒\n",
      "平均處理時間：0.028秒\n",
      "平均偵測時間：0.027秒\n"
     ]
    }
   ],
   "source": [
    "write_video = False # 是否寫入檔案\n",
    "all_object = True # 是否標記所有物件\n",
    "particular_obj = [0, 2] # 若否，則指定物件\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "frame_cnt = 0\n",
    "input_video = cv2.VideoCapture(input_path)\n",
    "max_frame = input_video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "fps = int(np.round(input_video.get(cv2.CAP_PROP_FPS)))\n",
    "\n",
    "if write_video:\n",
    "    codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    size = (int(input_video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(input_video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "    output_video = cv2.VideoWriter(output_path, codec, fps, size)\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "original_frame = Queue()\n",
    "preprc_frame = Queue()\n",
    "detection_data = Queue()\n",
    "detection_time = Queue()\n",
    "stop = False\n",
    "\n",
    "def getFrame_mt():\n",
    "    while not stop:\n",
    "        if preprc_frame.qsize() < fps:\n",
    "            ret, frame = input_video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "                \n",
    "            frame_pre = preProcessing(frame)\n",
    "            original_frame.put(frame)\n",
    "            preprc_frame.put(frame_pre)\n",
    "        else:\n",
    "            sleep(0.5)\n",
    "            \n",
    "def detection_mt():\n",
    "    total_dtime = 0\n",
    "    while not stop:\n",
    "        if preprc_frame.qsize() > 0:\n",
    "            frame_pre = preprc_frame.get()\n",
    "            bbox, dtime = detection(frame_pre)\n",
    "            \n",
    "            total_dtime += dtime\n",
    "            detection_data.put(bbox)\n",
    "            detection_time.put(total_dtime)\n",
    "        else:\n",
    "            sleep(0.001)\n",
    "            \n",
    "th1 = Thread(target = getFrame_mt)\n",
    "th2 = Thread(target = detection_mt)\n",
    "th1.start()\n",
    "th2.start()\n",
    "\n",
    "start_time = time()\n",
    "# ----------------------------------------------------------------------------------------------------- #\n",
    "while True:\n",
    "    if detection_data.qsize() > 0:\n",
    "        frame = original_frame.get()\n",
    "        bounding_box = detection_data.get()\n",
    "        \n",
    "        if not all_object:\n",
    "            bounding_box = objectFilter(bounding_box, particular_obj)\n",
    "        frame_drw = drawImage(frame, bounding_box)\n",
    "        \n",
    "        if write_video:\n",
    "            output_video.write(frame_drw)\n",
    "            \n",
    "        frame_cnt += 1\n",
    "        processingTime('video', time() - start_time, detection_time.get(), frame_cnt)\n",
    "        \n",
    "        if frame_cnt == 1:\n",
    "            cv2.namedWindow('Detection_Result', cv2.WINDOW_AUTOSIZE)\n",
    "        if not showResult('video', frame_drw):\n",
    "            stop = True\n",
    "            printString('程式手動停止', 60)\n",
    "            releaseVideo()\n",
    "            break\n",
    "            \n",
    "        elif frame_cnt == max_frame:\n",
    "            stop = True\n",
    "            printString('影片物件偵測完成', 58)\n",
    "            releaseVideo()\n",
    "            break           \n",
    "    else:\n",
    "        sleep(0.001) # delay 1ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
