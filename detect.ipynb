{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "#from tensorflow.python.keras.models import load_model\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.saved_model import tag_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'models/yolov4-default/yolov4.weights' #path to weights file\n",
    "classes_file = 'models/yolov4-default/classes.txt'\n",
    "model_path1 = 'models/yolov4-default/yolov4.h5'\n",
    "model_path2 = 'checkpoints/yolov4'\n",
    "\n",
    "input_size = 416 #define input size of export model\n",
    "score_thres = 0.2 #define score threshold'\n",
    "\n",
    "image = './data/kite.jpg' #path to input image\n",
    "output = 'result.png' #path to output image\n",
    "iou = 0.45 #iou threshold\n",
    "score = 0.25 #score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(model_path2, tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\User Profiles\\Desktop\\Personal Files\\Codes\\tensorflow-yolov4\\detect.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m boxes, scores, classes, valid_detections \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mcombined_non_max_suppression(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     boxes\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mreshape(boxes, (tf\u001b[39m.\u001b[39mshape(boxes)[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m4\u001b[39m)),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     scores\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     score_threshold\u001b[39m=\u001b[39mscore\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m pred_bbox \u001b[39m=\u001b[39m [boxes\u001b[39m.\u001b[39mnumpy(), scores\u001b[39m.\u001b[39mnumpy(), classes\u001b[39m.\u001b[39mnumpy(), valid_detections\u001b[39m.\u001b[39mnumpy()]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m image \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mdraw_bbox(original_image, pred_bbox, classes_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m image \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(image\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39muint8))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/User%20Profiles/Desktop/Personal%20Files/Codes/tensorflow-yolov4/detect.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m image\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32md:\\User Profiles\\Desktop\\Personal Files\\Codes\\tensorflow-yolov4\\core\\utils.py:122\u001b[0m, in \u001b[0;36mdraw_bbox\u001b[1;34m(image, bboxes, classes_path, show_label)\u001b[0m\n\u001b[0;32m    120\u001b[0m bbox_thick \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39m0.6\u001b[39m \u001b[39m*\u001b[39m (image_h \u001b[39m+\u001b[39m image_w) \u001b[39m/\u001b[39m \u001b[39m600\u001b[39m)\n\u001b[0;32m    121\u001b[0m c1, c2 \u001b[39m=\u001b[39m (coor[\u001b[39m1\u001b[39m], coor[\u001b[39m0\u001b[39m]), (coor[\u001b[39m3\u001b[39m], coor[\u001b[39m2\u001b[39m])\n\u001b[1;32m--> 122\u001b[0m cv2\u001b[39m.\u001b[39;49mrectangle(image, c1, c2, bbox_color, bbox_thick)\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m show_label:\n\u001b[0;32m    125\u001b[0m     bbox_mess \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m%.2f\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (classes[class_ind], score)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n>  - Can't parse 'rec'. Expected sequence length 4, got 2\n"
     ]
    }
   ],
   "source": [
    "original_image = cv2.imread(image)\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# image_data = utils.image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "image_data = cv2.resize(original_image, (input_size, input_size))\n",
    "image_data = image_data / 255.\n",
    "# image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "images_data = []\n",
    "for i in range(1):\n",
    "    images_data.append(image_data)\n",
    "images_data = np.asarray(images_data).astype(np.float32)\n",
    "\n",
    "batch_data = tf.constant(images_data)\n",
    "pred_bbox = infer(batch_data)\n",
    "for key, value in pred_bbox.items():\n",
    "    boxes = value[:, :, 0:4]\n",
    "    pred_conf = value[:, :, 4:]\n",
    "\n",
    "boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "    boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "    scores=tf.reshape(\n",
    "        pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "    max_output_size_per_class=50,\n",
    "    max_total_size=50,\n",
    "    iou_threshold=iou,\n",
    "    score_threshold=score\n",
    ")\n",
    "pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
    "\n",
    "image = utils.draw_bbox(original_image, pred_bbox, classes_file)\n",
    "image = Image.fromarray(image.astype(np.uint8))\n",
    "image.show()\n",
    "#image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)\n",
    "#cv2.imwrite(output, image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c7f24cc11f040a5450439addbf53847cc02767a77e59162e28b9055931e82da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
