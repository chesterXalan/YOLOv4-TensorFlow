{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "import core.utils as utils\n",
    "from core.yolov4 import filter_boxes\n",
    "#from tensorflow.python.keras.models import load_model\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.python.saved_model import tag_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'models/yolov4-default/yolov4.weights' #path to weights file\n",
    "classes_file = 'models/yolov4-default/classes.txt'\n",
    "model_path1 = 'models/yolov4-default/yolov4.h5'\n",
    "model_path2 = 'checkpoints/yolov4'\n",
    "\n",
    "input_size = 416 #define input size of export model\n",
    "score_thres = 0.2 #define score threshold'\n",
    "\n",
    "image = './data/kite.jpg' #path to input image\n",
    "output = 'result.png' #path to output image\n",
    "iou = 0.45 #iou threshold\n",
    "score = 0.25 #score threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "saved_model_loaded = tf.saved_model.load(model_path2, tags=[tag_constants.SERVING])\n",
    "infer = saved_model_loaded.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image = cv2.imread(image)\n",
    "original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# image_data = utils.image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "image_data = cv2.resize(original_image, (input_size, input_size))\n",
    "image_data = image_data / 255.\n",
    "# image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "images_data = []\n",
    "for i in range(1):\n",
    "    images_data.append(image_data)\n",
    "images_data = np.asarray(images_data).astype(np.float32)\n",
    "\n",
    "batch_data = tf.constant(images_data)\n",
    "pred_bbox = infer(batch_data)\n",
    "for key, value in pred_bbox.items():\n",
    "    boxes = value[:, :, 0:4]\n",
    "    pred_conf = value[:, :, 4:]\n",
    "\n",
    "boxes, scores, classes, valid_detections = tf.image.combined_non_max_suppression(\n",
    "    boxes=tf.reshape(boxes, (tf.shape(boxes)[0], -1, 1, 4)),\n",
    "    scores=tf.reshape(\n",
    "        pred_conf, (tf.shape(pred_conf)[0], -1, tf.shape(pred_conf)[-1])),\n",
    "    max_output_size_per_class=50,\n",
    "    max_total_size=50,\n",
    "    iou_threshold=iou,\n",
    "    score_threshold=score\n",
    ")\n",
    "pred_bbox = [boxes.numpy(), scores.numpy(), classes.numpy(), valid_detections.numpy()]\n",
    "\n",
    "image = utils.draw_bbox(original_image, pred_bbox, classes_file)\n",
    "image = Image.fromarray(image.astype(np.uint8))\n",
    "image.show()\n",
    "#image = cv2.cvtColor(np.array(image), cv2.COLOR_BGR2RGB)\n",
    "#cv2.imwrite(output, image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c7f24cc11f040a5450439addbf53847cc02767a77e59162e28b9055931e82da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
